TITLE: Random walk
AUTHOR: Torbj√∏rn Seland
DATE: today

TOC: on

===== Introduction =====
The last chapter will study a third way to model epidemic disease. This will be done by using random walk. This technique quite different from the other models presented earlier, by using Monte Carlo simulations and probabilities instead of differential equations, which have been in focus earlier. The first section will be a study of Monte Carlo methods and Random walk based on the paper from M.H. Jensen Ref. cite{hjorth2011computational}. The next sections will use the parameters from *English Boarding School* and *Walking Dead* to see if a Random walk system can expand the knowledge about epidemics. The model will be compared to the ODE system and PDE system from the previous chapters.   

===== Monte Carlo methods =====
Techniques from Monte Carlo are widely used in several fields as chemistry, physics, medicine, biology and in finance Ref. cite{hjorth2011computational}. These numerical methods can be seen in general terms as statistical simulations methods, which use random numbers to perform the simulations. The Metropolis algorithm is a central algorithm in this field, and is considered as one of the top ten algorithms during the last century Ref. cite{hjorth2011computational}. A Monte Carlo strategy require four terms to be understood to use this method. These are:
* Random variable
* probability distribution functions (PDF)
* moments of a PDE
* the pertinent variance $\sigma ^2$

=== Random variable ===
Random variable can be seen as stochastic variable, where the outcome cannot be presumed. Examples as tossing dice, flipping coins or gambling are based on this principle. Although the outcome is unknown, knowledge about the probability and the range can be studied. The numbers in the *domain* for two dice are
!bt
\begin{equation*}
{2,3,4,5,6,7,8,9,10,11,12}
\end{equation*}
!et
with the corresponding *probabilities* are
!bt
\begin{equation*}
{1,2,3,4,5,6,5,4,3,2,1}\frac{1}{36}
\end{equation*}
!et
By throwing two dice once, there is no guarantee that the result will be 7, though this has the highest probability. But by repeating this operation, the distribution would reflect the *probabilities* above. A stochastic variable can either be discrete or continuous, but will in both cases be denoted as capital letters, $X,Y$. A discrete example is the example above, where the domain is given with exact values,${x_1,x_2,x_3,...,x_n}$. The continuous case can be seen as the probability in a given area. An example can be the distance from a dart to the center, after a random thrown at a dartboard.

When using a computer to produce random number, they will in reality be pseudo random, since they have to be based on an algorithm. Therefore the choice of this algorithm is important. In this chapter, a generator of Marsaglia Ref. cite{marsaglia2003xorshift}

=== probability distribution functions (PDF) ===
The PDF is a function $p(x)$ on the domain that gives the probability or relative frequency for a outcome. In the discrete case, the function can be seen as
!bt
\begin{equation}
p(x) = Prob(X=x)
\end{equation}
!et
The PDF in the continuous is not able to directly depict the actual probability. The probability is instead defined as the density around $x$ with an infinitesimal interval. This can therefore be seen as an integral, since it is the density of the probability rather than the probability Ref.cite{hjorth2011computational}. This can be defined.
!bt
\begin{equation}
 Prob(a\leq X \leq b) = \int^b_a p(x)dx
\end{equation}
!et
And by quoting M.H. Jensen *Qualitatively speaking, a stochastic variable represents the values of numbers chosen as if by chance from some specified PDF so that the selection of a large set of these numbers reproduces this PDF.* Ref.cite{hjorth2011computational}. This sum up the relation between random variables and PDF. If this is not fulfilled, the group of stochastic variable does not fulfill the criteria for random numbers. 

CDF- *cumulative probability distribution function*

There are two properties that the PDF must fulfill. The first one is the size of $p(x)$. This has to be in the interval $0\geq p(x) \geq 1$, since the probability cannot be negative or larger than 1 for an event to happen. The sum of all events has to be 1, both for discrete and continuous PDFs, and can be seen as follows
!bt
\begin{equation}
	\begin{aligned}
    \sum_{x_i \in \mathbb{D}}\\
    \int_{x \in \mathbb{D}}
	\end{aligned}
\end{equation} 
!et

There are several distributions that are essential when looking at continuous PDFs. The two ones that will be used in this chapter are the uniform distribution.
!bt
\begin{equation} label{eq:uni_dist}
p(x) = \frac{1}{b-a}\theta(x-a)\theta(b-x)
\end{equation}
!et
with:
!bt
\begin{equation}
	\begin{aligned}
    \theta(x) = 0,\quad x < 0 \\
    \theta(x) = 1,\quad x \geq 0
	\end{aligned}
\end{equation}
!et
This distribution is natural to use, when a group of humans shall be evenly placed over an area. When comparing the ODE system from the first chapter and the uniformed distributed PDE system in previous chapter, Eq. (ref{eq:uni_dist}) is natural to use. To get a correct estimate, it is important that the set of random numbers is large enough. Gaussian distribution is the second one, this is often called normal distribution and can be seen in Eq.(ref{eq:gauss_dist})
!bt
\begin{equation} label{eq:gauss_dist}
	\begin{aligned}
    p(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp(-\frac{(x-\mu)^2}{2\sigma^2})
	\end{aligned}
\end{equation}
!et
This will give the same distribution as the Gaussian function used in the previous chapter. 


=== moments of a PDF ===
By define $h(x)$ as a arbitrary function, the *expectation value* can be written
!bt
\begin{equation}
    \langle h \rangle_X \equiv \int h(x)p(x)dx
\end{equation}
!et
Here defined on the domain of the stochastic variable $X$ with PDE $p(x)$. A more general way to write the expectation is by adding a power of,$n$, to the equation. This can now be seen as the *moments*. The $n$-th moment is defined
!bt
\begin{equation}
    \langle x^n \rangle \equiv \int x^np(x)dx
\end{equation}
!et
The value of $n$ can be sat to zero. This result in $\langle 1 \rangle$ and creates a normalization condition of $p$. The first order is called *mean* and are often defined with a $\mu$.
!bt
\begin{equation}
    \langle x \rangle = \mu \equiv \int xp(x)dx
\end{equation}
!et
This represents the average value of PDF and is often called the expectation value of $p$ Ref.cite{hjorth2011computational}.

=== The pertinent variance $\sigma ^2$ ===
*Central moments* is a special case of moments defined as
!bt
\begin{equation}
    \langle (x-\langle x \rangle)^n \rangle \equiv \int (x-\langle x \rangle)^np(x)dx
\end{equation}
!et
The first two central-moments are trivial and only result in 1 and 0, respectively for $n=0$ and $n=1$. But the second central-moment is more interesting to study. This is denoted as $\sigma^2_X$ or Var(X), called the variance. This can be shown.
!bt
\begin{equation}
    \sigma^2_X  = \langle x^2\rangle -\langle x \rangle^2 
\end{equation}
!et
The square root of the variance, $sigma = \sqrt{\langle (x-\langle x \rangle)^2 \rangle}$ is called *standard deviation*. This is the deviation from the mean of PDF, and can be seen as the spread around the mean of PDF.

===== Random walks =====
The previous section explained the technical aspects of Monte Carlo, as the principle and algorithms for producing random numbers. This section will study the importance of a proper selection of variables and importance sampling. The challenge when model a Monte Carlo simulation, is the appropriate selection of random states. It is important that this match the probability distribution, PDF. This will be done through a Markov process, which is a random walk with a selected probability for making a move. A good reason to choose Markov process, is that this will reach equilibrium state, after certain number of simulations. This can first be shown for a simple diffusion equation, which can be expanded to the simple PDE system used in the previous chapter.

=== Diffusion equation and random walks ===
The British Botanist R. Brown developed a theory by studying how pollen dispersed in water. This idea is called Brownian motion and can be used to describe a group of particles spreading. The function $w(x,t)dx$ can be defined as the probability of finding a given number of particles in an interval with size $dx$. This function is the $PDF$ as explained in the section above. The flux of particles that passing a point $x$, can be described by $j(x,t). This flow is proportionally with the gradient of the $PDF$,
!bt
\begin{equation}
j(x,t) = -D\frac{\partial w(x,t)}{\partial x}
\end{equation}
!et
$D$ is here the diffusion constant. This example can be seen as a closed experiment, where the concentration is conserved. The relation between the flux and the $PDF$ can also be expressed
!bt
\begin{equation}
\frac{\partial j(x,t)}{\partial x} = -\frac{\partial w(x,t)}{\partial t} 
\end{equation}
!et
And a diffusion equation can be expressed based on these two equations.
!bt
\begin{equation}
\frac{\partial w(x,t)}{\partial t} = D\frac{\partial^2 w(x,t)}{\partial x^2} 
\end{equation}
!et
The expectation value and the variance, $\sigma^2$, can be study. The expectation value for the function $f(x,t)$ can be defined as
!bt
\begin{equation}
\langle f(x,t) \rangle = \int^{\infty}_{-\infty} f(x,t) w(x,t)dx
\end{equation}
!et
The demands defined for the PDF in the previous section have to be fulfilled for $w(x,t)$. The normalization condition which is defined for this PDF require constraints for equation.
!bt
\begin{equation} label{eq:PDF_demands}
w(x= \pm \infty,t) = 0,\quad \frac{\partial^nw(x,t)}{\partial x^n}|_{x=\pm\infty} = 0 
\end{equation}
!et
This can be used to study the time derivative of the expectation value. The diffusion equation derived earlier can be used here.
!bt
\begin{equation}
\frac{\partial \langle f(x,t) \rangle}{\partial t} = \int^{\infty}_{-\infty} f(x,t) \frac{\partial w(x,t)}{\partial t}dx = D \int^{\infty}_{-\infty} f(x,t) \frac{\partial^2 w(x,t)}{\partial x^2}dx
\end{equation}
!et
By using integration by parts on the right side, the equation can be expressed,
!bt
\begin{equation} label{eq:disp_0}
\frac{\partial \langle f(x,t) \rangle}{\partial t} = D f(x,t) \frac{\partial w(x,t)}{\partial x}|_{x=\pm \infty} - 2D \int^{\infty}_{-\infty} \frac{\partial w(x,t)}{\partial x}dx
\end{equation}
!et
By using the demands from (ref{eq:PDF_demands}), the $\langle f(x,t) \rangle$ is independent of time. 
!bt
\begin{equation}
\frac{\partial \langle f(x,t) \rangle}{\partial t} = 0
\end{equation}
!et
Implying that if a simulation of a random walk with equal probability of jumping in each direction, will end up with the probability distribution centered around the initial position. This may not be the case for the variance. By using (ref{eq:disp_0}), the $\langle x^2 \rangle $ can be found. 
!bt
\begin{equation} 
\frac{\partial \langle x^2 \rangle}{\partial t} = D x^2 \frac{\partial w(x,t)}{\partial x}|_{x=\pm \infty} - 2D \int^{\infty}_{-\infty} x\frac{\partial w(x,t)}{\partial x}dx
\end{equation}
!et
Here, integration by parts can be used. This results in
!bt
\begin{equation}
\frac{\partial \langle x^2 \rangle}{\partial t} = D x w(x,t)|_{x=\pm \infty} + 2D \int^{\infty}_{-\infty} w(x,t)dx = 2D
\end{equation}
!et
this leads to
!bt
\begin{equation}
\langle x^2 \rangle = 2Dt
\end{equation}
!et
which gives the variance
!bt
\begin{equation} label{eq:diff_var}
\langle x^2 \rangle -\langle x \rangle^2 = 2Dt
\end{equation}
!et
And the square root of the variance can be expressed,
!bt
\begin{equation}
\sqrt{\langle x^2 \rangle -\langle x \rangle^2} = \sqrt{2Dt}
\end{equation}
!et
By comparing this with the displacement of a free particle, which moves with the function $x(t)=vt$ from the initial point, will the diffusion process moves with $\sqrt{\langle x^2 \rangle -\langle x \rangle^2} \propto \sqrt{t}$. This can be used to describe a random walk, and could say that a random walker escapes much more slowly than a free particle from the initial time. This can be seen in an example. 

=== Random walker ===
Now the random walker can be introduced in 1D. This can either jump to the left or the right with a lenght $\Delta x = l$. It is equal probability for both directions. $L=R=1/2$. Then the average displacement will be 
!bt
\begin{equation}
 \langle x(n) \rangle = \sum^n_i \Delta x_i = 0, \quad \Delta x_i = \pm l,
\end{equation}
!et
after $n$ jumps. The variance can be found by first finding $\langle x(n)^2 \rangle$.
!bt
\begin{equation}
\langle x(n)^2 \rangle = \left(\sum^n_i \Delta x_i\right)\left(\sum^n_j \Delta x_j\right) = \sum^n_i \Delta x_i^2 + \sum^n_i \Delta x_i \Delta x_j = l^2n
\end{equation}
!et
The last term here will disappear after enough steps.  
!bt
\begin{equation}
\sum^n_i \Delta x_i \Delta x_j = 0
\end{equation}
!et
This gives the variance
!bt
\begin{equation}
\langle x(n)^2 \rangle-\langle x(n) \rangle^2 = l^2n
\end{equation}
!et
Now this variance from a random walker can be coupled with the variance from the diffusion equation in the section above. By setting $n = t/\Delta t$. The random walker gets the following variance
!bt
\begin{equation}
\langle x(n)^2 \rangle-\langle x(n) \rangle^2 = l^2\frac{t}{\Delta t}
\end{equation}
!et
Then the diffusion constant in (ref{eq:diff_var}) can be replaced by
!bt
\begin{equation}
D = \frac{l^2}{\Delta t}
\end{equation}
!et
And the variance between these can be compared.

FIGURE:[plots/random_compare.png, height=500 width=800 frac=0.8] label{fig:gauss_random} 10000 random walkers placed at x=0 at t=0. Every step has the length $\Delta x = 0.01$ and with a random step every $\Delta t = 0.01$.

The standard deviation can be found for this simulation. This is given by the square root of the variance
!bt
\begin{equation}
\sigma = \sqrt{l^2\frac{t}{\Delta t}}
\end{equation}
!et

To study if the average random walker develops as expected, a table can with the outputs can be added. 

label{table:gauss_random}
|-----------------------------------------------|
|						|time=2     |time=8     |
|-----------------------------------------------|
|average displacement   |0.000662   | -0.002416 |
|standard deviation(SD) |0.1414     |  0.2828   |
|percent inside SD      |70.96 %    |69.02 %    |
|percent inside gauss   |68.26 %    |68.26 %    |
|-----------------------------------------------|

The average displacement and the standard deviation shows that a group of random walkes spread similar as a standard diffusion function. This result in a major group of random walkers. In the simulation in Fig.(ref{fig:gauss_random}), 10000 random walkers are used. By increasing the amount om random walkers, the precision will be better.

===== Epidemic in an English Boarding School =====
This example has been common for all three systems, and will be used in this chapter. The chance of getting infected requires a meeting between  infected person and a susceptible person..A random walker will after enough steps cover the whole area. A simulation is done for a student with a random position at initial time. 1000 random steps are performed every day, which results in a step every 90 seconds. The step length is set to 5.7024 m, and is based on the average distance a person walks every day. The simulation is performed for 15 days, which results in 15000 random steps. The size of the schoolyard is sat to 100 m x 100 m, and the disease can spread within a distance of 5 meters.

FIGURE:[plots/random_walk_days.png, height=300 width=900 frac=0.8] label{fig:random_walker_days} The positions a random walker has covered in 1,5 and 15 days. A random step with lenght 3.96 m is performed every minute. The positions are plotted for every ten minutes. 

Fig.(ref{fig:random_walker_days} shows that a random walker will be distributed over the area after enough steps. The students in the school are divided into three groups. The first group consists of susceptible students, and this group is at risk of getting infected. This group is described by $S$. The second group consists of infected students. The group is described by $I$. The last group consists of students who are immune to the disease. This group is described by $R$. The total number of students is $N=763$. The initial values are: $S_0=762$, $I_0=1$ and $R_0=0$. There are two parameters that are used in the simulation. The first parameter $r$, describes the gain of $I$ from the susceptible group, $S$. This is rate proportional to the number of susceptible and infecetive and is given by $rSI$. The second parameter $a$ describes the rate of removal of infective to the removed group, $R$. These two parameters are given by $r=2.18\cdot 10^{-3}$ and $a=0.44036$. The simulation is based on the ODE system given in *Epidemic models* :

!bt
\begin{equation} \label{eq:SIR_model_random}
	\begin{aligned} 
	\frac{dS}{dt} &= -rSI \\ 
	\frac{dI}{dt} &= rSI-aI \\ 
	\frac{dR}{dt} &= aI 
	\end{aligned}
\end{equation}
!et

The parameters $r$ and $a$ must be adapted to the random walk simulation. The parameter $r$ is used in
!bt
\begin{equation} label{eq:rSI}
rSI
\end{equation}
!et
is based on all possible combinations of $S$ and $I$. This will not be the case in a random simulation. The meetings in a random simulation depends on the number of random walkers and the possibility for a meeting. If the possibility is small, the susceptible student has to be close to an infected student to be infected. The number of meetings during one time step can be used to adjust the parameter. The following term has to be fulfilled:   
!bt
\begin{equation} label{eq:NoM}
r_{random}NoM_0 = rS_0I_0
\end{equation}
!et
Here $NoM_0$ is a constant value and represents number of meetings between the susceptible group and the infected group at initial time. This can be found by a numerical simulation of the random walkers. The number of meetings for the infected student during one day is simulated for 1000 rounds, the average value is $NoM=1905.223$. Now Eq.(ref{eq:NoM}) can be rewritten and $r_{random}$ can be expressed by known values: 
!bt
\begin{equation} label{eq:NoM}
	\begin{aligned} 
	r_{random} &= \frac{rS_0I_0}{NoM_0}
	\end{aligned}
\end{equation}
!et
The parameter $r_{random}$ is now used to calculate the risk of getting infected in a meeting between a susceptible student and an infected student. The value of $a$ also has to be adjusted. This parameter is only affected by the time. The random simulation is performed for 1000 random steps during one day. This means that there will be 1000 chances of being immune to the disease during 1 day, since a random number will be drawn every random step. A person can only get immune one time, therefore it is more interesting to see if a person stays infected during 1 day. All other results will cause an immune student. The chance of staying infected during one day is $In = 1-a$, which results in $In=0.55964$. The chance of staying infected for 1000 time steps during one day demands the following percent for each time step: $In^{\frac{1}{1000}}= 0.9994197$. Since all other solutions gives an immune student,the percent can be set to: $a_{random} = 1-In^{\frac{1}{1000}}= 0.00058$. A series of simulations can be done with these parameters. The average solution will be plotted against the solution from the ODE system given in Eq.(ref{eq:SIR_model_random}). The standard deviation for the random simulations is given.

FIGURE:[plots/english_school_random.png, height=500 width=500 frac=0.8] label{fig:english_school_random}Random walk compared to an ODE simulation of Eq.(ref{eq:SIR_model_random}. The random function is shown with a dashed line, with the standard deviation shown as the colored area around the dashed line. The random function is based on the average of a series of simulations. 
 

=== A Lower average value ===
By studying the results in Fig.(ref{fig:english_school_random}), one can see that the values of the random walk simulation is lower than for the ODE. The difference is low in the beginning of the simulation. This changes when the *Infected* group increases. This results in an increase of the combination between the *Susceptible* group and the *Infected* group. In an ODE simulation, this will lead to a rapid increase of the *Infected* group. Since the transformation for a student from the *Susceptible* group to the *Infected* group only requires one successful meeting, where successful is seen as the transmission of the disease. There will be no difference in the result if the transmission of the disease happens once or several times during one time step. This is reasonable to be the case when the amount of *Infected* increase.  

=== Threshold value ===
In the previous chapters, the threshold value was found for the epidemic systems. The reproduction rate could be used to check if the disease would develop into an epidemic disease. The reproduction rate can be seen in Eq.(ref{eq:rep_rate})
!bt
\begin{equation} label{eq:rep_rate}
R_0 = \frac{rS_0}{a}
\end{equation}
!et
If $R_0> 1$ was fulfilled, an epidemic situation would occur. The result will be $R_0 = 3.77$ with the parameters from the ODE simulation. When simulating the random walk, only 56 percent of the simulations resulted in an epidemic disease. 44 percent resulted in a transmission of the infected student to the *Removed* group, before the student was able to infect other students. This simulations were performed on a small group, and the results may differ in larger groups. A removal rate above one will not necessarily lead to an epidemic disease, if the group is small enough.
  
======= Zombiefication =======
The ODE system given in chapter *Epidemic models* will be used for this simulation. This can be seen in Eq.(ref{eq:seland_model_random}). The parameters has to be adjusted for this simulation, similar as shown for the English boarding school. Frederikkeplassen at Blindern will be used as the area where the simulations will be done. The area is estimated to be 100m x 100m and the disease will be able to spread if the distance is closer than 4 meters. There will be done three different simulations in this section, where the human intelligence will be taken into account. The total time of the simulations will be set to 34 minutes, and there will be performed 100 random walks each minute.       
!bt
\begin{equation} \label{eq:seland_model_random}
    \begin{aligned} 
    \frac{dS}{dt} =& \Sigma -(\beta+\mu \omega(t))SZ - \delta_SS \\
    \frac{dI}{dt} =& (\beta+\mu \omega(t))SZ - \varrho I - \delta_II\\
    \frac{dZ}{dt} =& \varrho I- (\alpha+\omega(t))SZ + \zeta R\\
    \frac{dR}{dt} =& \delta_SS +\delta_II -\zeta R + (\alpha+\omega(t))SZ 
    \end{aligned}
\end{equation}
!et

===== Random walk =====


MOVIE:[plots/english_school.webm, height=500 width=600]

#MOVIE:[plots/2D_zombie_three_phases_blindern_area_contourf.webm, height=500 width=600] Created with different diffusion constants. The groups of susceptible are placed in three different areas. 








======= Bibliography =======

BIBFILE: ../bibliography/papers.pub
